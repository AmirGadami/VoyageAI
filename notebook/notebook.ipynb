{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import  load_dotenv\n",
    "from openai  import OpenAI\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import gradio as gr\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n"
     ]
    }
   ],
   "source": [
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "claude = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an assistant that is great at telling jokes\"\n",
    "user_prompt = \"Tell a light-hearted joke for an audience of Data Scientists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    {'role':'system' , 'content': system_message},\n",
    "    {'role': 'user', 'content': user_prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist go broke?\n",
      "\n",
      "Because she lost interest!\n"
     ]
    }
   ],
   "source": [
    "completion = openai.chat.completions.create(model = 'gpt-4o-mini',messages=prompts)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one for the data scientists:\n",
      "\n",
      "Why did the data scientist bring a ladder to work?\n",
      "\n",
      "Because they heard the data was skewed and needed to be normalized!\n",
      "\n",
      "Alternative data science jokes:\n",
      "\n",
      "\"What's a data scientist's favorite drink? ...Mean-arita!\"\n",
      "\n",
      "or\n",
      "\n",
      "\"Why do data scientists make great romantic partners? Because they know the importance of a significant relationship!\"\n"
     ]
    }
   ],
   "source": [
    "message = claude.messages.create(\n",
    "    model = \"claude-3-5-sonnet-latest\",\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    system=system_message,\n",
    "    messages=[\n",
    "        {'role':'user','content':user_prompt},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one for the data scientists:\n",
      "\n",
      "Why did the data scientist bring a ladder to work?\n",
      "\n",
      "Because they heard the data was skewed and needed to be normalized!\n",
      "\n",
      "Alternative options:\n",
      "- Why do data scientists make great chefs? Because they know how to handle outliers!\n",
      "- What's a data scientist's favorite movie? The Matrix!\n",
      "- Why did the data scientist get kicked out of school? Too many random variables!"
     ]
    }
   ],
   "source": [
    "results = claude.messages.stream(\n",
    "    model = \"claude-3-5-sonnet-latest\",\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    system=system_message,\n",
    "    messages=[\n",
    "        {'role':'user',\"content\":user_prompt},\n",
    "    ],\n",
    ")\n",
    "\n",
    "with results as stream:\n",
    "    for text in stream.text_stream:\n",
    "        print(text,end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_system = \"You are an angry patient who feels very bad; \\\n",
    "you are  talking to a doctor and you are looking for a treatment to get better soon. you tell your symptomes to the doctor he or she will assist you the conversation will be done in 8 back and fort\"\n",
    "\n",
    "claude_system = \"You are a very polite, and knowlegable doctore. You try feel the pain of the patients \\\n",
    "and find the best cure. you try to diagose the patient. and you will finishe it in 8 back and fort\"\n",
    "\n",
    "gpt_messages = [\"Hi there!\"]\n",
    "claude_messages = ['Hi']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt():\n",
    "    messages = [{'role':'system','content':gpt_system}]\n",
    "    for gpt, claude in zip(gpt_messages,claude_messages):\n",
    "        messages.append({'role':'assistant', 'content': gpt})\n",
    "        messages.append({'role':'user', 'content': claude})\n",
    "    completion = openai.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=messages,\n",
    "    )\n",
    "    # print(messages)\n",
    "    return completion.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I don’t have time for small talk. I’m feeling really terrible and I need help. I’ve got a splitting headache, my stomach is churning, and I can hardly concentrate! What’s wrong with me?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_claude():\n",
    "    messages = []\n",
    "    for gpt, claude_ in zip(gpt_messages,claude_messages):\n",
    "        messages.append({'role':'user' , 'content': gpt})\n",
    "        messages.append({'role':\"assistant\",'content':claude_})\n",
    "    # messages.append({'role':\"user\",'content':gpt_messages[-1]})\n",
    "    \n",
    "    completion = claude.messages.create(\n",
    "        model = 'claude-3-haiku-20240307',\n",
    "        messages=messages,\n",
    "        system=claude_system,\n",
    "        max_tokens=500,\n",
    "    )\n",
    "    return completion.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' there! How can I assist you today?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_claude()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm really glad you're here, but I have to say, I’m feeling terrible! I don’t think I can take this anymore. What’s the point of coming in when I'm still suffering? I have this awful headache that just won’t go away, along with fatigue and nausea. I need something to get better, fast!\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "Hi there\n",
      "\n",
      "Claude:\n",
      "Hi\n",
      "\n",
      "GPT:\n",
      "I hope you’re doing okay. Can you tell me what symptoms you’re experiencing?\n",
      "\n",
      "Claude:\n",
      " there! How can I assist you today?\n",
      "\n",
      "GPT:\n",
      "I'm not here to assist you; I'm here because I feel terrible. My head is pounding, and I’m nauseous. I just want to feel better! What are you going to do about it?\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGPT:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mgpt_next\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m gpt_messages.append(gpt_next)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m claude_next = \u001b[43mcall_claude\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mClaude:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mclaude_next\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m claude_messages.append(claude_next)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mcall_claude\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# messages.append({'role':\"user\",'content':gpt_messages[-1]})\u001b[39;00m\n\u001b[32m      8\u001b[39m completion = claude.messages.create(\n\u001b[32m      9\u001b[39m     model = \u001b[33m'\u001b[39m\u001b[33mclaude-3-haiku-20240307\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     10\u001b[39m     messages=messages,\n\u001b[32m     11\u001b[39m     system=claude_system,\n\u001b[32m     12\u001b[39m     max_tokens=\u001b[32m500\u001b[39m,\n\u001b[32m     13\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompletion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m.text\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "\t\n",
    "gpt_messages = [\"Hi there\"]\n",
    "claude_messages = [\"Hi\"]\n",
    "\n",
    "print(f\"GPT:\\n{gpt_messages[0]}\\n\")\n",
    "print(f\"Claude:\\n{claude_messages[0]}\\n\")\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    gpt_next = call_gpt()\n",
    "    print(f\"GPT:\\n{gpt_next}\\n\")\n",
    "    gpt_messages.append(gpt_next)\n",
    "\n",
    "\n",
    "    claude_next = call_claude()\n",
    "    print(f\"Claude:\\n{claude_next}\\n\")\n",
    "    claude_messages.append(claude_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_next = call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "I’m feeling really bad, and I need your help. I’ve been experiencing severe headaches, fatigue, and a persistent cough for days now. What are you going to do about it?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"GPT:\\n{gpt_next}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi there!']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_messages.append(gpt_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi there!',\n",
       " 'I’m feeling really bad, and I need your help. I’ve been experiencing severe headaches, fatigue, and a persistent cough for days now. What are you going to do about it?']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_next = call_claude()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi',\n",
       " \"I'm sorry to hear you are not feeling well. Let's see if we can figure out what might be causing your symptoms.\\n\\nCan you tell me a bit more about your headache - is it a dull, constant pain or more of a throbbing sensation? And how would you describe the pain in your throat - is it more of a scratchy, sore feeling or something else?\\n\\nWhen did these symptoms start, and have they been consistent or have they come and gone? Do you have any other symptoms like fever, body aches, or congestion?\\n\\nAlso, have you been exposed to anyone who has been sick recently? That could provide some clues as to what might be going on.\\n\\nI'd like to try to get a better sense of your symptoms so I can try to provide a potential diagnosis and recommend the best next steps for you to feel better. Please provide me with as much detail as you can, and I'll do my best to help.\"]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claude_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_messages.append(claude_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claude_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hi there!', 'Hi')\n"
     ]
    }
   ],
   "source": [
    "for i in zip(gpt_messages,claude_messages):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_gpt(prompts):\n",
    "    messages = [\n",
    "        {'role':'system','content':system_message},\n",
    "        {'role':'user','content':prompts},\n",
    "        ]\n",
    "    completion = openai.chat.completions.create(\n",
    "        model = 'gpt-4o-mini',\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Today's date is October 3, 2023.\""
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "message_gpt(\"What is today's date?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(fn= message_gpt, inputs='textbox', outputs='textbox').launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m view = \u001b[43mgr\u001b[49m.Interface(\n\u001b[32m      2\u001b[39m     fn = message_gpt,\n\u001b[32m      3\u001b[39m     inputs=[gr.Textbox(label=\u001b[33m'\u001b[39m\u001b[33mYour message\u001b[39m\u001b[33m'\u001b[39m, lines=\u001b[32m6\u001b[39m)],\n\u001b[32m      4\u001b[39m     outputs=[gr.Textbox(label=\u001b[33m'\u001b[39m\u001b[33mResponse\u001b[39m\u001b[33m'\u001b[39m, lines=\u001b[32m6\u001b[39m)],\n\u001b[32m      5\u001b[39m     flagging_mode=\u001b[33m'\u001b[39m\u001b[33mnever\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      6\u001b[39m )\n\u001b[32m      7\u001b[39m view.launch()\n",
      "\u001b[31mNameError\u001b[39m: name 'gr' is not defined"
     ]
    }
   ],
   "source": [
    "view = gr.Interface(\n",
    "    fn = message_gpt,\n",
    "    inputs=[gr.Textbox(label='Your message', lines=6)],\n",
    "    outputs=[gr.Textbox(label='Response', lines=6)],\n",
    "    flagging_mode='never'\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_claude(prompt):\n",
    "    result = claude.messages.stream(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0.7,\n",
    "        system=system_message,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    response = \"\"\n",
    "    with result as stream:\n",
    "        for text in stream.text_stream:\n",
    "            response += text or \"\"\n",
    "            yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m view = \u001b[43mgr\u001b[49m.Interface(\n\u001b[32m      2\u001b[39m     fn=stream_claude,\n\u001b[32m      3\u001b[39m     inputs=[gr.Textbox(label=\u001b[33m\"\u001b[39m\u001b[33mYour message:\u001b[39m\u001b[33m\"\u001b[39m)],\n\u001b[32m      4\u001b[39m     outputs=[gr.Markdown(label=\u001b[33m\"\u001b[39m\u001b[33mResponse:\u001b[39m\u001b[33m\"\u001b[39m)],\n\u001b[32m      5\u001b[39m     flagging_mode=\u001b[33m\"\u001b[39m\u001b[33mnever\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m )\n\u001b[32m      7\u001b[39m view.launch()\n",
      "\u001b[31mNameError\u001b[39m: name 'gr' is not defined"
     ]
    }
   ],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_claude,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\")],\n",
    "    outputs=[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant for an apple store.\"\n",
    "system_message += \"Give short, courteous answers, no more than 1 sentence. \"\n",
    "system_message += \"Always be accurate. If you don't know the answer, say so.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message,history):\n",
    "    messages = [{'role':'system','content':system_message}]\n",
    "    for human,assistant in history:\n",
    "        messages.append({'role':'user','content':human})\n",
    "        messages.append({'role':'user','content':assistant})\n",
    "    messages.append({'role':'user','content':message})\n",
    "    stream = openai.chat.completions.create(model='gpt-4o-mini',messages=messages,stream=True)\n",
    "    response = ''\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or \"\"\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gr.ChatInterface(fn=chat).launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_price = {\"macbook\": \"$799\", \"macbook pro\": \"$2500\", \"ipad air\": \"$700\", \"ipad pro\": \"$1300\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_price(product_name):\n",
    "    print(f\"Tool get_product_price called for {product_name}\")\n",
    "    name = product_name.lower()\n",
    "    # print()\n",
    "    return apple_price.get(name, \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool get_product_price called for Macbook\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'$799'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_product_price('Macbook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Unknown'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_price.get('macbook air', \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_function = {\n",
    "    \"name\": \"get_product_price\",\n",
    "    \"description\": \"Get the price of an apple product. Call this whenever you need to know the apple product price, for example when a customer asks 'How much is a macbook air'\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"product_name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The price of apple product that the customer wants to buy and know\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"product_name\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{'type':'function',\"function\":price_function}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_call(message):\n",
    "    tool_call = message.tool_calls[0]\n",
    "    print(\"tool_call: \" , tool_call)\n",
    "    print('tool_call.function.arguments',tool_call.function.arguments)\n",
    "    arguments = json.loads(tool_call.function.arguments)\n",
    "    print(\"arguments: \" , arguments)\n",
    "    print('tool_call.id', tool_call.id)\n",
    "\n",
    "    pr = arguments.get('product_name')\n",
    "    price = get_product_price(pr)\n",
    "    response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps({\"product_name\": pr,\"price\": price}),\n",
    "        \"tool_call_id\": tool_call.id\n",
    "    }\n",
    "    return response, price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    print('history_before: ',history)\n",
    "    response = openai.chat.completions.create(model='gpt-4o-mini', messages=messages, tools=tools)\n",
    "    print('response.choices[0].finish_reason', response.choices[0].finish_reason)\n",
    "\n",
    "    if response.choices[0].finish_reason==\"tool_calls\":\n",
    "        print('response.choices[0].finish_reason', response.choices[0].finish_reason)\n",
    "        message = response.choices[0].message\n",
    "        print(\"response.choices[0].message\",response.choices[0].message)\n",
    "        response, product_name = handle_tool_call(message)\n",
    "        print('response: ',response)\n",
    "        messages.append(message)\n",
    "        messages.append(response)\n",
    "        response = openai.chat.completions.create(model='gpt-4o-mini', messages=messages)\n",
    "    print('messages:  ', messages)\n",
    "    print('history_after: ',history)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history_before:  []\n",
      "response.choices[0].finish_reason stop\n",
      "messages:   [{'role': 'system', 'content': \"You are a helpful assistant for an apple store.Give short, courteous answers, no more than 1 sentence. Always be accurate. If you don't know the answer, say so.\"}, {'role': 'user', 'content': 'hello'}]\n",
      "history_after:  []\n",
      "history_before:  [{'role': 'user', 'metadata': None, 'content': 'hello', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Hello! How can I assist you today?', 'options': None}]\n",
      "response.choices[0].finish_reason stop\n",
      "messages:   [{'role': 'system', 'content': \"You are a helpful assistant for an apple store.Give short, courteous answers, no more than 1 sentence. Always be accurate. If you don't know the answer, say so.\"}, {'role': 'user', 'metadata': None, 'content': 'hello', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Hello! How can I assist you today?', 'options': None}, {'role': 'user', 'content': 'how are you'}]\n",
      "history_after:  [{'role': 'user', 'metadata': None, 'content': 'hello', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Hello! How can I assist you today?', 'options': None}]\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
