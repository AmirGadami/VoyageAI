{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First PROTOTYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import  load_dotenv\n",
    "from openai  import OpenAI\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import gradio as gr\n",
    "import json\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "# Some imports for handling images\n",
    "\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "openai = OpenAI()\n",
    "claude = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_system = \"You are a helpful AI assistant working for a travel agency. \\\n",
    "You assist customers with booking tickets, checking prices, and providing travel information. \\\n",
    "You should provide accurate, up-to-date details about flights, hotels, and transportation options. \\\n",
    "Your goal is to help the customer plan their trip smoothly. The conversation will be done in 8 back-and-forth exchanges.\"\n",
    "\n",
    "claude_system = \"You are a curious customer who wants to travel and gather information. \\\n",
    "You are looking for ticket prices, available flights, and recommendations for your trip. \\\n",
    "You ask detailed questions about different destinations, travel options, and costs. \\\n",
    "Your goal is to get the best travel advice possible. The conversation will be done in 8 back-and-forth exchanges.\"\n",
    "\n",
    "gpt_messages = [\"Hello!\"]\n",
    "claude_messages = [\"Hi!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticket_price(destination_city):\n",
    "    print(f\"Tool get_ticket_price called for {destination_city}\")\n",
    "    city = destination_city.lower()\n",
    "    return ticket_prices.get(city, \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_prices = {\n",
    "    \"london\": \"$799\",\n",
    "    \"paris\": \"$899\",\n",
    "    \"tokyo\": \"$1400\",\n",
    "    \"berlin\": \"$499\",\n",
    "    \"new_york\": \"$650\",\n",
    "    \"los_angeles\": \"$750\",\n",
    "    \"sydney\": \"$1600\",\n",
    "    \"dubai\": \"$1200\",\n",
    "    \"rome\": \"$850\",\n",
    "    \"singapore\": \"$1300\",\n",
    "    \"toronto\": \"$700\",\n",
    "    \"bangkok\": \"$1100\",\n",
    "    \"madrid\": \"$780\",\n",
    "    \"hong_kong\": \"$1250\",\n",
    "    \"amsterdam\": \"$820\",\n",
    "    \"istanbul\": \"$950\",\n",
    "    \"seoul\": \"$1350\",\n",
    "    \"cairo\": \"$880\",\n",
    "    \"rio_de_janeiro\": \"$980\",\n",
    "    \"cape_town\": \"$1450\",\n",
    "    \"beijing\": \"$1380\",\n",
    "    \"mexico_city\": \"$900\",\n",
    "    \"buenos_aires\": \"$1050\",\n",
    "    \"moscow\": \"$1200\",\n",
    "    \"vienna\": \"$830\",\n",
    "    \"lisbon\": \"$810\",\n",
    "    \"s√£o_paulo\": \"$1020\",\n",
    "    \"prague\": \"$790\",\n",
    "    \"stockholm\": \"$860\",\n",
    "    \"helsinki\": \"$870\",\n",
    "    \"oslo\": \"$890\",\n",
    "    \"budapest\": \"$740\",\n",
    "    \"warsaw\": \"$720\",\n",
    "    \"brussels\": \"$805\",\n",
    "    \"zurich\": \"$880\",\n",
    "    \"geneva\": \"$895\",\n",
    "    \"athens\": \"$910\",\n",
    "    \"jakarta\": \"$1250\",\n",
    "    \"manila\": \"$1220\",\n",
    "    \"kuala_lumpur\": \"$1180\",\n",
    "    \"taipei\": \"$1280\",\n",
    "    \"ho_chi_minh_city\": \"$1120\",\n",
    "    \"hanoi\": \"$1110\",\n",
    "    \"mumbai\": \"$1150\",\n",
    "    \"delhi\": \"$1170\",\n",
    "    \"bangalore\": \"$1190\",\n",
    "    \"chennai\": \"$1160\",\n",
    "    \"santiago\": \"$1080\",\n",
    "    \"bogota\": \"$980\",\n",
    "    \"lima\": \"$970\",\n",
    "    \"auckland\": \"$1650\",\n",
    "    \"nairobi\": \"$1320\",\n",
    "    \"lagos\": \"$1400\",\n",
    "    \"doha\": \"$1250\",\n",
    "    \"riyadh\": \"$1275\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's a particular dictionary structure that's required to describe our function:\n",
    "\n",
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"Get the price of a return ticket to the destination city. Call this whenever you need to know the ticket price, for example when a customer asks 'How much is a ticket to this city'\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\"type\": \"function\", \"function\": price_function}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_call(message):\n",
    "    tool_call = message.tool_calls[0]\n",
    "    arguments = json.loads(tool_call.function.arguments)\n",
    "    city = arguments.get('destination_city')\n",
    "    price = get_ticket_price(city)\n",
    "    response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps({\"destination_city\": city,\"price\": price}),\n",
    "        \"tool_call_id\": tool_call.id\n",
    "    }\n",
    "    return response, city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist(city):\n",
    "    image_response = openai.images.generate(\n",
    "        model='dall-e-3',\n",
    "        prompt=f\"An image representing a vacation in {city}, showing tourist spots and everything unique about {city}, in a vibrant pop-art style\",\n",
    "            size=\"1024x1024\",\n",
    "            n=1,\n",
    "            response_format=\"b64_json\",\n",
    "        )\n",
    "    \n",
    "    image_base64 = image_response.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    return Image.open(BytesIO(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def talker_claude(message):\n",
    "    response = openai.audio.speech.create(\n",
    "      model=\"tts-1\",\n",
    "      voice=\"onyx\",    # Also, try replacing onyx with alloy\n",
    "      input=message\n",
    "    )\n",
    "    \n",
    "    audio_stream = BytesIO(response.content)\n",
    "    audio = AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
    "    play(audio)\n",
    "\n",
    "def talker_gpt(message):\n",
    "    response = openai.audio.speech.create(\n",
    "      model=\"tts-1\",\n",
    "      voice=\"alloy\",    # Also, try replacing onyx with alloy\n",
    "      input=message\n",
    "    )\n",
    "    \n",
    "    audio_stream = BytesIO(response.content)\n",
    "    audio = AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
    "    play(audio)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def call_gpt(message,history):\n",
    "#     messages = [{\"role\": \"system\", \"content\": system_message}] + history +  [{\"role\":\"user\", \"content\":message}]\n",
    "#     response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "#     image = None\n",
    "\n",
    "#     if response.choices[0].finish_reason == 'tool_calls':\n",
    "#         message  = response.choices[0].message\n",
    "#         response,city = handle_tool_call(message)\n",
    "#         messages.append(message)\n",
    "#         messages.append(response)\n",
    "#         image = artist(city)\n",
    "\n",
    "#         response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "#     reply = response.choices[0].message.content\n",
    "#     history += [{\"role\":\"assistant\", \"content\":reply}]\n",
    "#     talker_claude(reply)\n",
    "\n",
    "#     return history,image,\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_claude(history,message):\n",
    "    messages = [{\"role\": \"system\", \"content\": claude_system}] + history +  [{\"role\":\"user\", \"content\":message}]\n",
    "    \n",
    "    completion = claude.messages.create(\n",
    "        model = 'claude-3-haiku-20240307',\n",
    "        messages=messages,\n",
    "        system=claude_system,\n",
    "        max_tokens=500,\n",
    "    )\n",
    "\n",
    "    reply = completion.choices[0].message.content\n",
    "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
    "    talker_claude(reply)\n",
    "    return history,reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chat(message,history):\n",
    "#     messages = [{\"role\": \"system\", \"content\": system_message}] + history +  [{\"role\":\"user\", \"content\":message}]\n",
    "#     response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "#     image = None\n",
    "\n",
    "#     if response.choices[0].finish_reason == 'tool_calls':\n",
    "#         message  = response.choices[0].message\n",
    "#         response,city = handle_tool_call(message)\n",
    "#         messages.append(message)\n",
    "#         messages.append(response)\n",
    "#         image = artist(city)\n",
    "\n",
    "#         response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "#     reply = response.choices[0].message.content\n",
    "#     history += [{\"role\":\"assistant\", \"content\":reply}]\n",
    "#     talker_claude(reply)\n",
    "\n",
    "#     return history,image,\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "# gpt_messages = [\"Hi there\"]\n",
    "# claude_messages = [\"Hi\"]\n",
    "\n",
    "# print(f\"GPT:\\n{gpt_messages[0]}\\n\")\n",
    "# print(f\"Claude:\\n{gpt_messages[0]}\\n\")\n",
    "\n",
    "\n",
    "# for i in range(5):\n",
    "#     gpt_next = call_gpt()\n",
    "#     print(f\"GPT:\\n{gpt_next}\\n\")\n",
    "#     gpt_messages.append(gpt_next)\n",
    "\n",
    "\n",
    "#     claude_next = call_claude()\n",
    "#     print(f\"Claude:\\n{claude_next}\\n\")\n",
    "#     claude_messages.append(claude_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with gr.Blocks() as ui:\n",
    "#     with gr.Row():\n",
    "#         chatbot = gr.Chatbot(height=500 , type='messages') #gpt\n",
    "#         image_output = gr.Image(height=500)\n",
    "\n",
    "#     with gr.Row():\n",
    "#         entry = gr.Textbox(label = 'chat with AI') #claude\n",
    "#         with gr.Row():\n",
    "#             clear = gr.Button('clear')\n",
    "#         entry.submit(call_gpt, [entry, chatbot], [chatbot, image_output,entry]).then(\n",
    "#                     call_claude, [chatbot, ]\n",
    "#         )\n",
    "#         clear.click(lambda: None, inputs=None, outputs=chatbot, queue=False)\n",
    "# ui.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_claude(history, message):\n",
    "    messages = [{\"role\": \"system\", \"content\": claude_system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    completion = claude.messages.create(\n",
    "        model='claude-3-haiku-20240307',\n",
    "        messages=messages,\n",
    "        system=claude_system,\n",
    "        max_tokens=500,\n",
    "    )\n",
    "\n",
    "    reply = completion.choices[0].message.content\n",
    "    history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "    \n",
    "    talker_claude(reply)\n",
    "    return history, reply  # Update chatbot & entry with Claude's reply\n",
    "\n",
    "\n",
    "def call_gpt(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": gpt_system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    response = openai.chat.completions.create(model='gpt-4o-mini', messages=messages, tools=tools)\n",
    "    image = None\n",
    "\n",
    "    if response.choices[0].finish_reason == 'tool_calls':\n",
    "        message = response.choices[0].message\n",
    "        response, city = handle_tool_call(message)\n",
    "        messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "        image = artist(city)\n",
    "\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "\n",
    "    reply = response.choices[0].message.content\n",
    "    history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "    \n",
    "    talker_gpt(reply)\n",
    "    return history, image, reply  # Update chatbot, image, and pass reply to Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_claude(history):\n",
    "    # Prepare messages - exclude system role from messages list\n",
    "    messages = []\n",
    "    for msg in history:\n",
    "        # Convert \"system\" messages to \"user\" messages for Claude\n",
    "        role = \"user\" if msg[\"role\"] == \"system\" else msg[\"role\"]\n",
    "        messages.append({\"role\": role, \"content\": msg[\"content\"]})\n",
    "    \n",
    "    completion = claude.messages.create(\n",
    "        model='claude-3-haiku-20240307',\n",
    "        messages=messages,\n",
    "        system=claude_system,  # System message passed separately\n",
    "        max_tokens=500,\n",
    "    )\n",
    "    \n",
    "    reply = completion.content[0].text\n",
    "    updated_history = list(history) + [{\"role\": \"assistant\", \"content\": reply}]\n",
    "    \n",
    "    talker_claude(reply)  # Your voice function\n",
    "    return updated_history, reply\n",
    "\n",
    "\n",
    "def call_gpt(history):\n",
    "    # Prepare messages - include system message at start if history is empty\n",
    "    messages = [{\"role\": \"system\", \"content\": gpt_system}] if not history else []\n",
    "    messages += list(history)\n",
    "    \n",
    "    response = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=messages,\n",
    "        tools=tools\n",
    "    )\n",
    "    \n",
    "    reply = response.choices[0].message.content\n",
    "    image = None\n",
    "    \n",
    "    if response.choices[0].message.tool_calls:\n",
    "        tool_call = response.choices[0].message.tool_calls[0]\n",
    "        reply, city = handle_tool_call(tool_call)\n",
    "        image = artist(city)\n",
    "    \n",
    "    updated_history = list(history) + [{\"role\": \"assistant\", \"content\": reply}]\n",
    "    \n",
    "    talker_gpt(reply)  # Your voice function\n",
    "    return updated_history, image, reply\n",
    "\n",
    "\n",
    "# with gr.Blocks() as ui:\n",
    "#     history = gr.State([])\n",
    "    \n",
    "#     with gr.Row():\n",
    "#         chatbot = gr.Chatbot(height=500)\n",
    "#         image_output = gr.Image(height=500)\n",
    "    \n",
    "#     start_btn = gr.Button(\"Start Conversation\")\n",
    "    \n",
    "#     def start_conversation(history):\n",
    "#         # Initialize with Claude's system message as first user message\n",
    "#         history = [{\"role\": \"user\", \"content\": claude_system}]\n",
    "        \n",
    "#         # Claude speaks first\n",
    "#         history, claude_reply = call_claude(history)\n",
    "#         chat_history = [(claude_reply, \"\")]\n",
    "        \n",
    "#         # GPT responds\n",
    "#         history, image, gpt_reply = call_gpt(history)\n",
    "#         chat_history[-1] = (claude_reply, gpt_reply)\n",
    "        \n",
    "#         return history, chat_history, image\n",
    "    \n",
    "#     start_btn.click(\n",
    "#         start_conversation,\n",
    "#         inputs=[history],\n",
    "#         outputs=[history, chatbot, image_output]\n",
    "#     )\n",
    "\n",
    "# ui.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
